{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e5672",
   "metadata": {},
   "source": [
    "# Custom Chatbot Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6841fd44",
   "metadata": {},
   "source": [
    "**Purpose**:GPT models are built by learning from past sentences and other data, so they cannot respond to the most recent information. For example, fashion trends change every year, so GPT models cannot answer such questions or give ambiguous answers. In this project, I decided to use **RAG**(Retrieval Augmented Generation) to use fashion data in the chat responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3926e4",
   "metadata": {},
   "source": [
    "## Load liblary and default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "53bfa639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import openai\n",
    "from openai.embeddings_utils import get_embedding, distances_from_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa273eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"YOUR API KEY\"\n",
    "COMPLETION_MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4c5f",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "TODO: In the cells below, load your chosen dataset into a `pandas` dataframe with a column named `\"text\"`. This column should contain all of your text data, separated into at least 20 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c69b83a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82 entries, 0 to 81\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   URL     82 non-null     object\n",
      " 1   Trends  82 non-null     object\n",
      " 2   Source  82 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.0+ KB\n"
     ]
    }
   ],
   "source": [
    "path = \"data/*\"\n",
    "data_path = glob.glob(path)[-1]\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7679b2",
   "metadata": {},
   "source": [
    "**Observation**: Checking the column names in the data frame shows that TEXT does not exist. <br>\n",
    "**Todo**: Check data to change column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70519e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>text</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.refinery29.com/en-us/fashion-trend...</td>\n",
       "      <td>2023 Fashion Trend: Red. Glossy red hues took ...</td>\n",
       "      <td>7 Fashion Trends That Will Take Over 2023 — Sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.refinery29.com/en-us/fashion-trend...</td>\n",
       "      <td>2023 Fashion Trend: Cargo Pants. Utilitarian w...</td>\n",
       "      <td>7 Fashion Trends That Will Take Over 2023 — Sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.refinery29.com/en-us/fashion-trend...</td>\n",
       "      <td>2023 Fashion Trend: Sheer Clothing. \"Bare it a...</td>\n",
       "      <td>7 Fashion Trends That Will Take Over 2023 — Sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.refinery29.com/en-us/fashion-trend...</td>\n",
       "      <td>2023 Fashion Trend: Denim Reimagined. From dou...</td>\n",
       "      <td>7 Fashion Trends That Will Take Over 2023 — Sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.refinery29.com/en-us/fashion-trend...</td>\n",
       "      <td>2023 Fashion Trend: Shine For The Daytime. The...</td>\n",
       "      <td>7 Fashion Trends That Will Take Over 2023 — Sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  \\\n",
       "0  https://www.refinery29.com/en-us/fashion-trend...   \n",
       "1  https://www.refinery29.com/en-us/fashion-trend...   \n",
       "2  https://www.refinery29.com/en-us/fashion-trend...   \n",
       "3  https://www.refinery29.com/en-us/fashion-trend...   \n",
       "4  https://www.refinery29.com/en-us/fashion-trend...   \n",
       "\n",
       "                                                text  \\\n",
       "0  2023 Fashion Trend: Red. Glossy red hues took ...   \n",
       "1  2023 Fashion Trend: Cargo Pants. Utilitarian w...   \n",
       "2  2023 Fashion Trend: Sheer Clothing. \"Bare it a...   \n",
       "3  2023 Fashion Trend: Denim Reimagined. From dou...   \n",
       "4  2023 Fashion Trend: Shine For The Daytime. The...   \n",
       "\n",
       "                                              Source  \n",
       "0  7 Fashion Trends That Will Take Over 2023 — Sh...  \n",
       "1  7 Fashion Trends That Will Take Over 2023 — Sh...  \n",
       "2  7 Fashion Trends That Will Take Over 2023 — Sh...  \n",
       "3  7 Fashion Trends That Will Take Over 2023 — Sh...  \n",
       "4  7 Fashion Trends That Will Take Over 2023 — Sh...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c22f798",
   "metadata": {},
   "source": [
    "**Observation**: Columns with column name Trend have text information about fashion<br>\n",
    "**Todo**：Change column name from Trends to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a595980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82 entries, 0 to 81\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   URL     82 non-null     object\n",
      " 1   text    82 non-null     object\n",
      " 2   Source  82 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.0+ KB\n"
     ]
    }
   ],
   "source": [
    "if \"Trends\" in df.columns:\n",
    "    df = df.rename(columns = {\"Trends\":\"text\"})\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35074e",
   "metadata": {},
   "source": [
    "**Observation**: Dataframe reading data from csv has more than 20 rows including `text` column in column name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae769871",
   "metadata": {},
   "source": [
    "## Custom Query Completion\n",
    "\n",
    "TODO: In the cells below, compose a custom query using your chosen dataset and retrieve results from an OpenAI `Completion` model. You may copy and paste any useful code from the course materials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc8faa7",
   "metadata": {},
   "source": [
    "### Generating Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9cc2a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in range(0, len(df), batch_size):\n",
    "    # Send text data to OpenAI model to get embeddings\n",
    "    response = openai.Embedding.create(\n",
    "        input=df.iloc[i:i+batch_size][\"text\"].tolist(),\n",
    "        engine=EMBEDDING_MODEL_NAME\n",
    "    )\n",
    "    \n",
    "    # Add embeddings to list\n",
    "    embeddings.extend([data[\"embedding\"] for data in response[\"data\"]])\n",
    "\n",
    "# Add embeddings list to dataframe\n",
    "df[\"embeddings\"] = embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3e857b",
   "metadata": {},
   "source": [
    "### Create a Function that Finds Related Pieces of Text for a Given Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8b6e1f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows_sorted_by_relevance(question, df):\n",
    "    \"\"\"\n",
    "    Function that takes in a question string and a dataframe containing\n",
    "    rows of text and associated embeddings, and returns that dataframe\n",
    "    sorted from least to most relevant for that question\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get embeddings for the question text\n",
    "    question_embeddings = get_embedding(question, engine=EMBEDDING_MODEL_NAME)\n",
    "    \n",
    "    # Make a copy of the dataframe and add a \"distances\" column containing\n",
    "    # the cosine distances between each row's embeddings and the\n",
    "    # embeddings of the question\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"distances\"] = distances_from_embeddings(\n",
    "        question_embeddings,\n",
    "        df_copy[\"embeddings\"].values,\n",
    "        distance_metric=\"cosine\"\n",
    "    )\n",
    "    \n",
    "    # Sort the copied dataframe by the distances and return it\n",
    "    # (shorter distance = more relevant so we sort in ascending order)\n",
    "    df_copy.sort_values(\"distances\", ascending=True, inplace=True)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cb63f90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(question, df, max_token_count):\n",
    "    \"\"\"\n",
    "    Given a question and a dataframe containing rows of text and their\n",
    "    embeddings, return a text prompt to send to a Completion model\n",
    "    \"\"\"\n",
    "    # Create a tokenizer that is designed to align with our embeddings\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    \n",
    "    # Count the number of tokens in the prompt template and question\n",
    "    prompt_template = \"\"\"\n",
    "Answer the question based on the context below, and if the question\n",
    "can't be answered based on the context, say \"I don't know\"\n",
    "\n",
    "Context: \n",
    "\n",
    "{}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {}\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    current_token_count = len(tokenizer.encode(prompt_template)) + \\\n",
    "                            len(tokenizer.encode(question))\n",
    "    \n",
    "    context = []\n",
    "    for text in get_rows_sorted_by_relevance(question, df)[\"text\"].values:\n",
    "        \n",
    "        # Increase the counter based on the number of tokens in this row\n",
    "        text_token_count = len(tokenizer.encode(text))\n",
    "        current_token_count += text_token_count\n",
    "        \n",
    "        # Add the row of text to the list if we haven't exceeded the max\n",
    "        if current_token_count <= max_token_count:\n",
    "            context.append(text)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return prompt_template.format(\"\\n\\n###\\n\\n\".join(context), question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a1e1e354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(\n",
    "    question, df, max_prompt_tokens=1800, max_answer_tokens=150\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a question, a dataframe containing rows of text, and a maximum\n",
    "    number of desired tokens in the prompt and response, return the\n",
    "    answer to the question according to an OpenAI Completion model\n",
    "    \n",
    "    If the model produces an error, return an empty string\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = create_prompt(question, df, max_prompt_tokens)\n",
    "    \n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=COMPLETION_MODEL_NAME,\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_answer_tokens\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783f146",
   "metadata": {},
   "source": [
    "## Custom Performance Demonstration\n",
    "\n",
    "TODO: In the cells below, demonstrate the performance of your custom query using at least 2 questions. For each question, show the answer from a basic `Completion` model query as well as the answer from your custom query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a990fe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def without_RAG_response(question):\n",
    "    response = openai.Completion.create(\n",
    "        model=COMPLETION_MODEL_NAME,\n",
    "        prompt=question,\n",
    "        max_tokens=150)\n",
    "    response = response[\"choices\"][0][\"text\"].replace(\"\\n\",\"\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11fdc0",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "94fc2e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is type of pants 2023 Fashion Trend \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4901c850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There is no specific type of pants that is predicted to be a fashion trend in 2023. Fashion trends are constantly changing and evolving, and it is impossible to accurately predict what will be popular five years in advance. However, some general trends in pants that may continue in 2023 include high-waisted styles, wide-leg or flared trousers, and statement prints or patterns.'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_RAG_response(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bd7a093b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cargo pants are a type of pants that are part of the 2023 fashion trend.'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(question, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e86e37c",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6f646989",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is type of shirt 2023 Fashion Trend \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "11c07a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am an AI and do not have the capability to predict future fashion trends for 2023. It would depend on the current fashion trends and consumer preferences at that time. The type of shirt that will be in trend could range from basic t-shirts, to button-down shirts, to more unique and modern styles.'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_RAG_response(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "10f31488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pinstripe tailoring.'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(question, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fefb741",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d122be",
   "metadata": {},
   "source": [
    "The original model avoided explicit responses, but the model using RAG presented specific designs of clothing, such as pinstripe shirts and cargo pants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ac3128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
